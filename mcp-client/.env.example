# 通用配置
# ===========================================
TZ=Asia/Shanghai


# MCP Client Web服务配置
# ===========================================
# Chainlit 框架配置
CHAINLIT_AUTH_SECRET="8Z$9@,BzJv*sxlyfj9JVWDIltov5kx%Buc*kA>O>.oLDsEwGuD.Zm~2y3vBk,m_A"
CHAINLIT_HOST=127.0.0.1
CHAINLIT_PORT=9003
CHAINLIT_AUTH_ENABLED=true


# LLM 模型配置 (OpenAI和Ollama至少要配置一个, 要配置的模型需要支持tool调用)
# ===========================================
# OpenAI 配置
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_API_KEY=
# 列出要用到的 OpenAI 模型，如果多个，请以英文逗号分隔
CHAINLIT_CHAT_OPENAI_MODELS=
# Ollama 配置（本地模型）
OLLAMA_BASE_URL=http://localhost:11434
# 列出要用到的 Ollama 模型，如果多个，请以英文逗号分隔
OLLAMA_MODELS=
# 可选，对话的默认模型 (需要在上方的 CHAINLIT_CHAT_OPENAI_MODELS 或 OLLAMA_MODELS 中)
CHAINLIT_CHAT_DEFAULT_MODEL=


# MinIO 对象存储配置
# ===========================================
MINIO_ENDPOINT=http://localhost:9000
MINIO_BASE_URL=http://localhost:9000
MINIO_USERNAME=minio
MINIO_PASSWORD=minio1234
MINIO_REGION=us-east-1
MINIO_BUCKET=files
